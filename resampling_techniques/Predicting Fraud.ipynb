{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook looks at the fraud dataset available on kaggle: \n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('percent fraud in dataset', round(fraud.Class.value_counts()[1] / fraud.Class.value_counts()[0] * 100, 2), 'percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_features = fraud.ix[:,2:4].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,28*4))\n",
    "gs = gridspec.GridSpec(28, 1)\n",
    "for i, cn in enumerate(fraud[v_features]):\n",
    "    ax = plt.subplot(gs[i])\n",
    "    sns.distplot(fraud[cn][fraud.Class == 1], bins=50)\n",
    "    sns.distplot(fraud[cn][fraud.Class == 0], bins=50)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_title('histogram of feature: ' + str(cn))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes of only Fraud and Normal transactions.\n",
    "fraud_samples = fraud[fraud.Class == 1]\n",
    "normal = fraud[fraud.Class == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = fraud_samples.sample(frac=0.03, random_state=0)\n",
    "sample = pd.concat([sample, normal.sample(frac = 0.03, random_state=0)], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_fraud = fraud_samples.iloc[~fraud_samples.index.isin(sample.index,), :]\n",
    "rest_normal = normal.iloc[~normal.index.isin(sample.index,), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = rest_fraud.sample(frac=0.03, random_state=0)\n",
    "test = pd.concat([test, rest_normal.sample(frac = 0.03, random_state=0)], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total number of samples:', len(sample), \n",
    "      '\\npercent fraud in dataset', round(sample.Class.value_counts()[1] / sample.Class.value_counts()[0] * 100, 2), 'percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total number of samples:', len(test), \n",
    "      '\\npercent fraud in dataset', round(test.Class.value_counts()[1] / test.Class.value_counts()[0] * 100, 2), 'percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sample.pop('Class')\n",
    "X = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[['V2', 'V3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test.pop('Class')\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[['V2', 'V3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## not a very intelligent classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf', probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('fitting SVM..')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting decision regions\n",
    "x_min, x_max = X.values[:, 0].min() - 1, X.values[:, 0].max() + 1\n",
    "y_min, y_max = X.values[:, 1].min() - 1, X.values[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "ax.contourf(xx, yy, Z, alpha=0.4)\n",
    "ax.scatter(X.values[:, 0], X.values[:, 1], c=y, s=20, edgecolor='k')\n",
    "ax.set_title('Kernel SVM')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## look at confusion matrix and roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve, classification_report\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.heatmap(conf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-0.0017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy:', accuracy_score(y_test, clf.predict(X_test)))\n",
    "print('recall:', recall_score(y_test, clf.predict(X_test)))\n",
    "print('precision:', precision_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute fpr, tpr, thresholds and roc auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test.values.ravel(), pd.DataFrame(clf.predict_proba(X_test))[1].values.ravel())\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc, alpha=0.5)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resampling using smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "sm = SMOTE(k_neighbors=1, ratio='minority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kind = [ros, sm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundaries(clf, X_sampled):\n",
    "    # Plotting decision regions\n",
    "    x_min, x_max = X_sampled[:, 0].min() - 1, X_sampled[:, 0].max() + 1\n",
    "    y_min, y_max = X_sampled[:, 1].min() - 1, X_sampled[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                         np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    return xx, yy, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, figsize=(12, 12))\n",
    "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "axs = axs.ravel()\n",
    "\n",
    "count = 0\n",
    "for each in kind:\n",
    "    print(each)\n",
    "    X_sampled, y_sampled = each.fit_sample(X, y)\n",
    "    \n",
    "    print('fitting SVM..')\n",
    "    clf.fit(X_sampled, y_sampled)\n",
    "    \n",
    "    xx, yy, Z = plot_decision_boundaries(clf, X_sampled)\n",
    "    axs[count].contourf(xx, yy, Z, alpha=0.4)\n",
    "    axs[count].scatter(X.values[:, 0], X.values[:, 1], c=y, s=20, edgecolor='k', alpha=0.2)\n",
    "    axs[count].set_title('Kernel SVM ')\n",
    "    \n",
    "    count +=1\n",
    "    axs[count].scatter(X_sampled[:, 0], X_sampled[:, 1], c=y_sampled, s=20, edgecolor='k', alpha=0.2)\n",
    "    axs[count].set_title('Kernel SVM ')\n",
    "    \n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.heatmap(conf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy:', accuracy_score(y_test, clf.predict(X_test)))\n",
    "print('recall:', recall_score(y_test, clf.predict(X_test)))\n",
    "print('precision:', precision_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute fpr, tpr, thresholds and roc auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test.values.ravel(), pd.DataFrame(clf.predict_proba(X_test))[1].values.ravel())\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label='AUC = %0.2f'% roc_auc, alpha=0.5)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
